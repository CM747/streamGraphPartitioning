<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        
        <link href="style/index.css" rel="stylesheet">
        
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        
        <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">

        <title>Streaming Graph Partitioning</title>
    </head>
    <header>
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mynavbar">
            <div class="container">
                <a class="navbar-brand" href="/">CS328: Introduction to Data Science</a>
            </div>
        </nav>
    </header>
    <body>
        <section id="header" style="padding-top: 10rem;">
            <h1 class="display-4" style="font-family: 'Roboto', sans-serif; font-weight: 900;">Analysis of Stream Graph Partitioning algorithms</h1>
        </section>

        <hr>

        <section id="authors">
            <div class="d-flex justify-content-around text-center">
                <div>
                    <h6>Authors</h6>
                    <p>Aditya Garg<br>Anshuman Yadav<br>Chandan Maji<br>Ojas Mithbavkar</p>
                </div>
                <div>
                    <h6>Roll</h6>
                    <p>17110003<br>17110020<br>17110037<br>17110083</p>
                </div>
            </div>
        </section>

        <hr>

        <section id="contents">
            <div>
                <h4>Contents</h4>
                <div style="padding: 1rem;">
                    <h6><a href="#intro">Intoduction &#8594</a></h6>
                    <h6><a href="#streamingModel">Streaming Model &#8594</a></h6>
                    <h6><a href="#implementation">Implementation and Visualization &#8594</a></h6>
                    <h6><a href="#evaluation">Evaluation &#8594</a></h6>
                    <h6><a href="#conclusion">Conclusion &#8594</a></h6>
                    <h6><a href="#refs">References &#8594</a></h6>
                </div>
            </div>
        </section>

        <hr>

        <section id="intro" class="section_heading">
            <div>
                <h2 class="display-4">Introduction</h2>
                <hr>
                <p class="lead">In this digital era, graph datasets are increasing rapidly with each day. For example take the World Wide Web where crawls of large search engines consists of over one trillion of links and expected to exceed ten trillion within a year. Even individual websites like Facebook and Twitter have billions of social relations. Also biological networks like protein interaction networks are of similar sizes. 
                </p>
                <p class="lead">These graphs contain huge information, but performing computations on them is becoming challenging as the graphs grow in size. A standard approach is to distribute the graph over a cluster of nodes, but if large amount of data have to be moved then performing computations become expensive. And without partitioning, communication becomes a limiting factor in scaling up the system.</p>
                <p class="lead">We need good graph partitioning algorithms because the graphs that we encounter in real world are not random. The edges display a great deal of locality. This shows that there must be some partition in the graph that is better than random cuts. Also since inter machine communication is more expensive than inter process communication therefore we need good partitioning algorithms for distributed systems. Existing graph partitioning heuristics have high computation and communication costs on large graphs. Since the graphs have to loaded in clusters, we try to partition the graph at the same time when we are streaming the graph. A graph loader is a program that reads graph data from disk to clusters. Our aim is to find a partition close to the optimal balanced partition using as little computation as possible. This problem is known as streaming graph partitioning.</p>
            </div>
        </section>

        

        <section id="streamingModel" class="section_heading" >
            <div>
                <h2 class="display-4">Streaming Model</h2>
                <hr>
                <p class="lead">We consider k machines/partitions each of capacity C. Therefore the total capacity kC is large enough to hold the whole graph. The streaming order of the graph nodes can be random or it can be the result of either DFS or BFS on graph.
                </p>
                <p class="lead">
                    As the nodes arrive, the algorithm decides to place each node in one of the k partitions. Once a node is assigned a partition, it is not moved to any other partition.
                </p>
                <p class="lead">
                    Our model has a serial input and a single graph loader. This is somewhat unrealistic as in real world there are multiple graph loaders working in parallel on independent portions of the stream. The heuristics used consider only depth 1 information of nodes i.e. immediate neighbours. The heuristic will be able to access the entire subgraph formed by the vertices previously seen and also all the edges involving a vertex that is already seen. 
                    Some algorithms also use a buffer of size C so it will allow the algorithm to place any node in the buffer instead of directly in front of the stream allowing for faster loads.
                </p>

                <div class="my-5">
                    <h3>Heuristics</h3>

                    <div class="mx-5">
                        <strong>Notations:</strong>
                        <ul style="list-style-type:none; font-style: italic;">
                            <li>k- number of partitions, each with capacity constraint C.</li>
                            <li>v - node arriving at time t.</li>
                            <li>Γ(v) - set of neighbours of v.</li>
                            <li>P<sub>t</sub> - set of partitions at time instant t.</li>
                            <li>P<sub>t</sub>(i) - Partition of index i from set P<sub>t</sub>.</li>
                            <li>ind - index of the chosen partition.</li>
                        </ul>
                    </div>
                    <ul style="list-style-type: decimal;">
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Balanced</strong>:
                                Assign v to a partition of minimum size. Break ties randomly.
                            </p>
                            <div class="d-flex justify-content-around" style="font-style: italic;">
                                ind = arg min { |Pt(i)| }
                            </div>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Chunking</strong>:
                                Divide the stream in chunks of size C and fill partitions in order.
                            </p>
                            <div class="d-flex justify-content-around" style="font-style: italic;">
                                ind =⌈t/C⌉
                            </div>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Hashing</strong>:
                                Given a hash function H: V → { 1 … k}, assign v to ind = H(v) where H(v) = (v mod k ) + 1. This will give the same partition as Balanced heuristic.
                            </p>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Weighted Deterministic Greedy</strong>:
                                Assign v to the partition with most edges.
                            </p>
                            <div class="d-flex justify-content-around" style="font-style: italic;">
                                ind = argmax{ |Pt(i) ∩ Γ(v)| w(t,i) } 
                                <br>where w(t,i) is the penalty function w(t,i) = 1 for unweighted greedy
                                <br>= 1 - ( |Pt(i)|/C ) for linear weighted
                                <br>= 1 - exp{ | Pt(i) | - C } for exponentially weighted
                            </div>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Weighted Random Greedy:</strong>:
                                Assign v using the probability distribution given by
                            </p>
                            <div class="d-flex justify-content-around" style="font-style: italic;">
                                Prob(i) = |Pt(i) ∩ Γ(v)| w(t,i)/Z where Z is the normalizing constant.
                            </div>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong> Weighted Triangles</strong>:
                                Assign v using
                            </p>
                            <div class="d-flex justify-content-around" style="font-style: italic;">
                                E(S,T) - edges between sets S,T ; w(t,i) is same as before.
                            </div>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Balance Big</strong>:
                                Partition incoming high degree nodes using the Balanced heuristic and low degree nodes with Deterministic greedy algorithm.
                            </p>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Prefer Big</strong>:
                                Maintain a buffer of size C. Allocate all the high degree nodes with Balanced method. If the buffer has only low degree nodes, use Deterministic Greedy method.
                            </p>
                        </li>
                        <li class="heuristic">
                            <p class="lead">
                                <strong>Avoid Big</strong>:
                                Maintain a buffer of size C. Assign all small nodes in the buffer using greedy. If buffer has all large nodes, use Deterministic Greedy.
                            </p>
                        </li>
                    </ul>
                    <p>For the last 2 algorithms, we take high degree nodes/ large nodes as top d % of nodes sorted by degree. We chose d=5.</p>
                </div>

                <div class="my-5">
                    <h3>Stream Orders</h3>
                    <p class="lead">We consider 3 stream ordering:</p>
                    <ul style="list-style-type: decimal;">
                        <li>
                            <p class="lead">
                                <strong>Random</strong>:
                                Vertices arrive in a order given by a random permutation of the vertices. This is a standard ordering in streaming literature.
                            </p>
                        </li>
                        <li>
                            <p class="lead">
                                <strong>BFS</strong>:
                                A starting node is selected at random from each connected component of the graph and breadth first search is done from that starting node. The ordering of the connected components is random.
                            </p>
                        </li>
                        <li>
                            <p class="lead">
                                <strong>DFS</strong>:
                                Identical to BFS ordering except depth first search is used.
                            </p>
                        </li>
                    </ul>
                </div>

                <div class="my-5">
                    <h3>Datasets</h3>
                    <ul>
                        <li>
                            <p class="lead">
                                <strong>Ego-facebook</strong> - It has 2.9K nodes and around 3K edges. It is an example of sparse network.
                            </p>
                        </li>
                        <li>
                            <p class="lead">
                                <strong>Wiki-vote</strong> - This network has 7.1K nodes and approximately 103K edges.
                            </p>
                        </li>
                    </ul>
                </div>
            </div>
        </section>
        
        <section id="implementation" class="section_heading">
            <div>
                <h2 class="display-4">Implementation and Visualization</h2>
                <hr>
                <p>Code Link: <a href="">
                </a></p>

                <table>
                    <tr>
                        <td>
                            <h6>Chucking:</h6>
                            <img src="data/gifs/chunking.gif" height="400" width="400">
                        </td>
                        <td>
                            <h6>Weighted Triangles:</h6>
                            <img src="data/gifs/weighted_triangles.gif" height="400" width="400">
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <h6>Random Greedy:</h6>
                            <img src="data/gifs/random_greedy.gif" height="400" width="400">
                        </td>
                        <td>
                            <h6>Deterministic Greedy (Linearly Weighted):</h6>
                            <img src="data/gifs/Linearly_weighted.gif" height="400" width="400">
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <h6>Deterministic Greedy (Exponentially Weighted):</h6>
                            <img src="data/gifs/Exponentially_Weighted.gif" height="400" width="400">
                        </td>
                        <td>
                            <h6>Balance Big:</h6>
                            <img src="data/gifs/Balance_big.gif" height="400" width="400" data-cover="data/gifs/Balance_big.png" class="giffy-img">
                        </td>
                    </tr>
                </table>
            </div>
        </section>

        
        
        <section id="evaluation" class="section_heading">
            <div>
                <h2 class="display-4">Evaluation</h2>
                <hr>
                <p class="lead">
                    Our main evaluation criteria is the ratio of total cross-partition edges and the total edges in the graph. The lower this value, the more successful an algorithm is.
                    <br><br>For each dataset we present the results of the heuristics:
                </p>
                <ul class="lead" style="list-style-type: decimal;">
                    <li>
                        <strong>Wiki-vote</strong>
                        <div class="d-flex justify-content-around">
                            <img src="data/wikiVoteResults.png" height="400px" width="650px">
                        </div>
                    </li>
                    <li>
                        <strong>Ego-facebook</strong>
                        <div class="d-flex justify-content-around">
                            <img src="data/facebookResults.png" height="400px" width="650px">
                        </div>
                    </li>
                </ul>
            </div>

        </section>



        <section id="conclusion" class="section_heading">
            <div>
                <h2 class="display-4">Conclusion</h2>
                <hr>
                
            </div>
        </section>

        <hr>

        <section id="refs" class="section_heading">
            <div>
                <h2 class="display-4">References</h2>
                <hr>
                <p>
                    [1] Stanton, Isabelle, and Gabriel Kliot. "Streaming graph partitioning for large distributed graphs." In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 1222-1230. 2012.
                </p>
                <p>
                    [2] https://snap.stanford.edu/data/
                </p>
            </div>
        </section>


        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        
        <script src="scripts/giffy.js"></script>
        <script>
            $('.giffy-img').giffy();
        </script>


    </body>
</html>